#!/usr/bin/env python3

import os
import sys
import time
import logging
import json
import gc
import sqlite3
from pathlib import Path

sys.path.append(str(Path(__file__).resolve().parent.parent))

import polars as pl
from deterministic_vrp_solver.utils import (
    load_orders_data_lazy, load_couriers_data,
    aggregate_orders_by_polygon_lazy, calculate_polygon_portal,
    filter_polygons_by_size, optimize_polygon_processing_order
)
from deterministic_vrp_solver.polygon.optimizer import optimize_all_polygons_hybrid
from deterministic_vrp_solver.route_optimizer import optimize_courier_routes
from deterministic_vrp_solver.solution_generator import generate_solution
from deterministic_vrp_solver.decomposed_distance_provider import DecomposedDistanceProvider
from deterministic_vrp_solver.reinforcement_scheduler import ReinforcementScheduler

def get_fast_db_connection(db_path: str) -> sqlite3.Connection:
    """–ë—ã—Å—Ç—Ä–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ SQLite"""
    conn = sqlite3.connect(db_path, timeout=30.0)
    
    # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
    conn.execute("PRAGMA journal_mode=WAL")
    conn.execute("PRAGMA synchronous=NORMAL")
    conn.execute("PRAGMA cache_size=50000")
    conn.execute("PRAGMA temp_store=MEMORY")
    conn.execute("PRAGMA mmap_size=134217728")  # 128MB mmap
    conn.execute("PRAGMA page_size=4096")
    
    return conn

def build_ports_database(ports_db_path: str, polygon_ports: dict, durations_conn: sqlite3.Connection) -> None:
    """–°–æ–∑–¥–∞–µ—Ç –ë–î —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –º–µ–∂–¥—É –ø–æ—Ä—Ç–∞–º–∏ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø–æ—Ä—Ç–æ–≤ –ø–æ–ª–∏–≥–æ–Ω–æ–≤."""
    if os.path.exists(ports_db_path):
        os.remove(ports_db_path)
    conn = sqlite3.connect(ports_db_path)
    cur = conn.cursor()
    cur.execute("CREATE TABLE IF NOT EXISTS port_distances (from_port INTEGER, to_port INTEGER, distance REAL)")
    # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ—Ä—Ç—ã
    all_ports = sorted({p for ports in polygon_ports.values() for p in ports})
    # –ó–∞–ø–æ–ª–Ω—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä –ø–æ—Ä—Ç–æ–≤
    dcur = durations_conn.cursor()
    for i, fp in enumerate(all_ports):
        for tp in all_ports:
            dcur.execute("SELECT d FROM dists WHERE f = ? AND t = ?", (fp, tp))
            row = dcur.fetchone()
            dist = row[0] if row and row[0] and row[0] > 0 else 0
            cur.execute("INSERT INTO port_distances (from_port, to_port, distance) VALUES (?, ?, ?)", (fp, tp, dist))
    conn.commit()
    conn.close()

def build_warehouse_ports_database(warehouse_ports_db_path: str, polygon_ports: dict, durations_conn: sqlite3.Connection) -> None:
    """–°–æ–∑–¥–∞–µ—Ç –ë–î —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –æ—Ç —Å–∫–ª–∞–¥–∞ (ID=0) –¥–æ –∫–∞–∂–¥–æ–≥–æ –ø–æ—Ä—Ç–∞."""
    if os.path.exists(warehouse_ports_db_path):
        os.remove(warehouse_ports_db_path)
    conn = sqlite3.connect(warehouse_ports_db_path)
    cur = conn.cursor()
    cur.execute("CREATE TABLE IF NOT EXISTS warehouse_port_distances (port_id INTEGER PRIMARY KEY, distance REAL)")
    all_ports = sorted({p for ports in polygon_ports.values() for p in ports})
    dcur = durations_conn.cursor()
    for port_id in all_ports:
        dcur.execute("SELECT d FROM dists WHERE f = ? AND t = ?", (0, port_id))
        row = dcur.fetchone()
        dist = row[0] if row and row[0] and row[0] > 0 else 0
        cur.execute("INSERT OR REPLACE INTO warehouse_port_distances (port_id, distance) VALUES (?, ?)", (port_id, dist))
    conn.commit()
    conn.close()

def create_decomposed_test():
    """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç —Å –¥–µ–∫–æ–º–ø–æ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π"""
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('test_decomposed_system.log'),
            logging.StreamHandler()
        ]
    )
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —É—Ä–æ–≤–µ–Ω—å DEBUG —Ç–æ–ª—å–∫–æ –¥–ª—è reinforcement_scheduler
    logging.getLogger('reinforcement_scheduler').setLevel(logging.INFO)
    logger = logging.getLogger(__name__)
    
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ —Å –¥–µ–∫–æ–º–ø–æ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π")
    start_time = time.time()
    
    try:
        root = Path(__file__).resolve().parent.parent
        data_dir = root / "ml_ozon_logistic"
        orders_file = data_dir / "ml_ozon_logistic_dataSetOrders.json"
        couriers_file = data_dir / "ml_ozon_logistic_dataSetCouriers.json"
        db_file = root / "durations.sqlite"
        
        if not orders_file.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –∑–∞–∫–∞–∑–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {orders_file}")
        if not couriers_file.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –∫—É—Ä—å–µ—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {couriers_file}")
        if not db_file.exists():
            raise FileNotFoundError(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {db_file}")
        
        logger.info("=== –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===")
        
        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–∫–∞–∑–æ–≤...")
        orders_lf = load_orders_data_lazy(str(orders_file))
        
        # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        logger.info("=== –û–¢–õ–ê–î–ö–ê: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===")
        orders_df_sample = orders_lf.collect()
        logger.info(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤: {len(orders_df_sample)}")
        logger.info(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª–∏–≥–æ–Ω–æ–≤: {orders_df_sample['MpId'].n_unique()}")
        logger.info(f"–ü—Ä–∏–º–µ—Ä—ã –ø–æ–ª–∏–≥–æ–Ω–æ–≤: {orders_df_sample['MpId'].head(10).to_list()}")
        
        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –∫—É—Ä—å–µ—Ä–æ–≤...")
        couriers_df, warehouse_info = load_couriers_data(str(couriers_file))
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫—É—Ä—å–µ—Ä–æ–≤ –¥–æ 100 –¥–ª—è —Ç–µ—Å—Ç–∞
        if len(couriers_df) > 100:
            logger.info(f"–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫—É—Ä—å–µ—Ä–æ–≤ —Å {len(couriers_df)} –¥–æ 100")
            couriers_df = couriers_df.head(100)
        
        logger.info("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")
        conn = get_fast_db_connection(str(db_file))
        
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(couriers_df)} –∫—É—Ä—å–µ—Ä–æ–≤")
        
        logger.info("–ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ–ª–∏–≥–æ–Ω–æ–≤...")
        # –ò—Å–∫–ª—é—á–∞–µ–º –∑–∞–∫–∞–∑—ã —Å–æ —Å–∫–ª–∞–¥–∞ (MpId=0) –∏–∑ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
        orders_lf_filtered = orders_lf.filter(pl.col('MpId') != 0)
        polygon_stats = aggregate_orders_by_polygon_lazy(orders_lf_filtered)
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(polygon_stats)} –ø–æ–ª–∏–≥–æ–Ω–æ–≤ –≤ –ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        
        # –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–µ 300 –ø–æ–ª–∏–≥–æ–Ω–æ–≤
        polygon_stats_300 = polygon_stats.head(300)
        
        logger.info(f"–í—ã–±—Ä–∞–Ω–æ {len(polygon_stats_300)} –ø–æ–ª–∏–≥–æ–Ω–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞")
        
        filtered_polygons = filter_polygons_by_size(polygon_stats_300, min_size=1, max_size=20)
        optimized_polygon_order = optimize_polygon_processing_order(filtered_polygons)
        
        logger.info(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(filtered_polygons)} –ø–æ–ª–∏–≥–æ–Ω–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        logger.info("=== –®–∞–≥ 2: –í—ã–±–æ—Ä –ø–æ—Ä—Ç–æ–≤ –ø–æ–ª–∏–≥–æ–Ω–æ–≤ ===")
        # –ü—Ä–æ—Å—Ç–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: –±–µ—Ä–µ–º –¥–æ 3 —Ç–æ—á–µ–∫-–∑–∞–∫–∞–∑–æ–≤ –∫–∞–∫ –ø–æ—Ä—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª–∏–≥–æ–Ω–∞
        polygon_ports = {}
        for row in filtered_polygons.iter_rows(named=True):
            order_ids = row['order_ids']
            ports = order_ids[:3] if isinstance(order_ids, list) else []
            polygon_ports[row['MpId']] = ports
        ports_db_path = str(Path(__file__).resolve().parent / "data" / "ports_database.sqlite")
        build_ports_database(ports_db_path, polygon_ports, conn)

        logger.info("=== –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ –ë–î —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –æ—Ç —Å–∫–ª–∞–¥–∞ –∫ –ø–æ—Ä—Ç–∞–º ===")
        warehouse_ports_db_path = str(Path(__file__).resolve().parent / "data" / "warehouse_ports_database.sqlite")
        build_warehouse_ports_database(warehouse_ports_db_path, polygon_ports, conn)
        
        logger.info("=== –®–∞–≥ 4: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–ª–∏–≥–æ–Ω–æ–≤ ===")
        
        service_times = {}
        optimized_polygons = optimize_all_polygons_hybrid(
            optimized_polygon_order, 
            str(db_file), 
            service_times,
            max_workers=1
        )
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –±–µ–∑ PolygonValidator
        q25 = optimized_polygons['total_cost'].quantile(0.25)
        q50 = optimized_polygons['total_cost'].quantile(0.50)
        q75 = optimized_polygons['total_cost'].quantile(0.75)
        q90 = optimized_polygons['total_cost'].quantile(0.90)
        logger.info(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø–æ–ª–∏–≥–æ–Ω–æ–≤:")
        logger.info(f"   Q25: {q25:.0f} —Å–µ–∫")
        logger.info(f"   Q50: {q50:.0f} —Å–µ–∫")
        logger.info(f"   Q75: {q75:.0f} —Å–µ–∫")
        logger.info(f"   Q90: {q90:.0f} —Å–µ–∫")
        too_expensive = optimized_polygons.filter(pl.col('total_cost') > 43200)
        if len(too_expensive) > 0:
            logger.warning(f"–ù–∞–π–¥–µ–Ω–æ {len(too_expensive)} –ø–æ–ª–∏–≥–æ–Ω–æ–≤ –¥–æ—Ä–æ–∂–µ –ª–∏–º–∏—Ç–∞")
            optimized_polygons = optimized_polygons.filter(pl.col('total_cost') <= 43200)
            logger.info(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–æ—Å—å {len(optimized_polygons)} –ø–æ–ª–∏–≥–æ–Ω–æ–≤")
        
        logger.info(f"–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(optimized_polygons)} –ø–æ–ª–∏–≥–æ–Ω–æ–≤")
        
        logger.info("–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ä—Ç–∞–ª–æ–≤ –ø–æ–ª–∏–≥–æ–Ω–æ–≤...")
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫—É portal_id, —Ç.–∫. –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–ª–∏–≥–æ–Ω–æ–≤ –µ—ë –Ω–µ –¥–æ–±–∞–≤–ª—è–µ—Ç
        if 'portal_id' not in optimized_polygons.columns:
            optimized_polygons = optimized_polygons.with_columns(pl.lit(0).alias('portal_id'))
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–∫–∞–∑—ã –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø–æ–ª–∏–≥–æ–Ω–æ–≤, –∏—Å–∫–ª—é—á–∞—è —Å–∫–ª–∞–¥ (MpId=0)
        selected_mp_ids = set(polygon_stats_300['MpId'].to_list())
        orders_df = load_orders_data_lazy(str(orders_file)).filter(
            pl.col('MpId').is_in(selected_mp_ids) & (pl.col('MpId') != 0)
        ).collect()
        
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(orders_df)} –∑–∞–∫–∞–∑–æ–≤ –¥–ª—è {len(selected_mp_ids)} –ø–æ–ª–∏–≥–æ–Ω–æ–≤")
        
        for row in optimized_polygons.iter_rows(named=True):
            mp_id = row['MpId']
            order_ids = row['order_ids']
            
            polygon_orders = orders_df.filter(pl.col('MpId') == mp_id)
            lats = polygon_orders['Lat'].to_list()
            longs = polygon_orders['Long'].to_list()
            
            portal_id = calculate_polygon_portal(conn, order_ids, lats, longs)
            
            optimized_polygons = optimized_polygons.with_columns(
                pl.when(pl.col('MpId') == mp_id)
                .then(pl.lit(portal_id))
                .otherwise(pl.col('portal_id'))
                .alias('portal_id')
            )
        
        # –ù–µ —É–¥–∞–ª—è–µ–º orders_df, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∞ –Ω—É–∂–Ω–∞ –ø–æ–∑–∂–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ—à–µ–Ω–∏—è
        # del orders_df
        # gc.collect()
        
        logger.info("=== –®–∞–≥ 5: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–ª–∏–≥–æ–Ω–∞—Ö –¥–ª—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ ===")
        
        logger.info(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª–∏–≥–æ–Ω–æ–≤: {len(optimized_polygons)}")
        logger.info(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª–∏–≥–æ–Ω–æ–≤ —Å –ø–æ—Ä—Ç–∞–º–∏: {len(polygon_ports)}")
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–ª–∏–≥–æ–Ω–∞—Ö –¥–ª—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        polygon_info_for_decomposition = {}
        
        for row in optimized_polygons.iter_rows(named=True):
            polygon_id = row['MpId']
            
            # –ò—Å–∫–ª—é—á–∞–µ–º —Å–∫–ª–∞–¥ (ID=0) –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            if polygon_id == 0:
                continue
                
            ports = polygon_ports.get(polygon_id, [])
            cost = row['total_cost']
            portal_id = row['portal_id']
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –æ—Ç –ø–æ—Ä—Ç–æ–≤ –¥–æ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –ø—É–Ω–∫—Ç–∞ (–ø–æ—Ä—Ç–∞–ª–∞)
            portal_distances = {}
            for port_id in ports:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º durations.sqlite –¥–ª—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –æ—Ç –ø–æ—Ä—Ç–∞ –¥–æ –ø–æ—Ä—Ç–∞–ª–∞
                cursor = conn.cursor()
                cursor.execute(
                    "SELECT d FROM dists WHERE f = ? AND t = ?",
                    (port_id, portal_id)
                )
                result = cursor.fetchone()
                if result and result[0] is not None and result[0] > 0:
                    distance = result[0]
                else:
                    # –ï—Å–ª–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º 0 (–ø–æ—Ä—Ç —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –ø–æ—Ä—Ç–∞–ª–æ–º)
                    distance = 0
                portal_distances[port_id] = distance
            
            polygon_info_for_decomposition[polygon_id] = {
                'ports': ports,
                'cost': cost,
                'portal_distances': portal_distances,
                'portal_id': portal_id
            }
        
        logger.info(f"–°–æ–∑–¥–∞–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–ª–∏–≥–æ–Ω–∞—Ö: {len(polygon_info_for_decomposition)}")
        if len(polygon_info_for_decomposition) > 0:
            sample_polygon = list(polygon_info_for_decomposition.keys())[0]
            sample_info = polygon_info_for_decomposition[sample_polygon]
            logger.info(f"–ü—Ä–∏–º–µ—Ä –ø–æ–ª–∏–≥–æ–Ω–∞ {sample_polygon}:")
            logger.info(f"  –ü–æ—Ä—Ç—ã: {sample_info['ports']}")
            logger.info(f"  –°—Ç–æ–∏–º–æ—Å—Ç—å: {sample_info['cost']}")
            logger.info(f"  Portal ID: {sample_info['portal_id']}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–æ–ª–∏–≥–æ–Ω 9340
            if 9340 in polygon_info_for_decomposition:
                logger.info(f"–ü–æ–ª–∏–≥–æ–Ω 9340 –Ω–∞–π–¥–µ–Ω –≤ polygon_info_for_decomposition")
                info_9340 = polygon_info_for_decomposition[9340]
                logger.info(f"  –ü–æ—Ä—Ç—ã: {info_9340['ports']}")
                logger.info(f"  –°—Ç–æ–∏–º–æ—Å—Ç—å: {info_9340['cost']}")
            else:
                logger.warning(f"–ü–æ–ª–∏–≥–æ–Ω 9340 –ù–ï –Ω–∞–π–¥–µ–Ω –≤ polygon_info_for_decomposition")
                logger.info(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–æ–ª–∏–≥–æ–Ω—ã: {list(polygon_info_for_decomposition.keys())[:10]}")
        else:
            logger.error("polygon_info_for_decomposition –ø—É—Å—Ç–æ–π!")
        
        logger.info("=== –®–∞–≥ 6: –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–ª–∏–≥–æ–Ω–æ–≤ –∫—É—Ä—å–µ—Ä–∞–º —Å –¥–µ–∫–æ–º–ø–æ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π ===")
        
        courier_service_times = {}
        
        with open(couriers_file, 'r') as f:
            couriers_data = json.load(f)
        
        for courier in couriers_data['Couriers']:
            courier_id = courier['ID']
            courier_service_times[courier_id] = {}
            
            if 'ServiceTimeInMps' in courier and courier['ServiceTimeInMps'] is not None:
                for mp_service in courier['ServiceTimeInMps']:
                    mp_id = mp_service['MpID']
                    service_time = mp_service['ServiceTime']
                    courier_service_times[courier_id][mp_id] = service_time
        
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã —Å–µ—Ä–≤–∏—Å–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–∞ –¥–ª—è {len(courier_service_times)} –∫—É—Ä—å–µ—Ä–æ–≤")
        
        # –°–æ–∑–¥–∞–µ–º –¥–µ–∫–æ–º–ø–æ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä
        decomposed_provider = DecomposedDistanceProvider(
            durations_db_path=str(db_file),
            ports_db_path=ports_db_path,
            warehouse_ports_db_path=warehouse_ports_db_path
        )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä
        decomposed_provider.__enter__()
        decomposed_provider.set_polygon_info(polygon_info_for_decomposition)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = decomposed_provider.get_statistics()
        logger.info(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã:")
        logger.info(f"   –ü–æ–ª–∏–≥–æ–Ω–æ–≤: {stats['total_polygons']}")
        logger.info(f"   –í—Å–µ–≥–æ –ø–æ—Ä—Ç–æ–≤: {stats['total_ports']}")
        logger.info(f"   –°—Ä–µ–¥–Ω–µ–µ –ø–æ—Ä—Ç–æ–≤ –Ω–∞ –ø–æ–ª–∏–≥–æ–Ω: {stats['avg_ports_per_polygon']:.2f}")
        
        logger.info("–ó–∞–ø—É—Å–∫ RL –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —Å –¥–µ–∫–æ–º–ø–æ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π...")
        optimized_polygons_filtered = optimized_polygons.filter(pl.col('MpId') != 0)
        logger.info(f"–ò—Å–∫–ª—é—á–µ–Ω —Å–∫–ª–∞–¥ –∏–∑ –ø–æ–ª–∏–≥–æ–Ω–æ–≤: {len(optimized_polygons)} -> {len(optimized_polygons_filtered)}")
        scheduler = ReinforcementScheduler(
            optimized_polygons_filtered,
            couriers_df,
            max_time_per_courier=43200,
            distance_provider=decomposed_provider,
            courier_service_times=courier_service_times,
            use_parallel=True,
            num_workers=4,
        )
        assignment = scheduler.solve(optimized_polygons_filtered, couriers_df, max_time_per_courier=43200)
        
        total_assigned = sum(len(polygons) for polygons in assignment.values())
        active_couriers = sum(1 for polygons in assignment.values() if polygons)
        
        logger.info(f"–ù–∞–∑–Ω–∞—á–µ–Ω–æ {total_assigned} –ø–æ–ª–∏–≥–æ–Ω–æ–≤")
        logger.info(f"–ê–∫—Ç–∏–≤–Ω—ã—Ö –∫—É—Ä—å–µ—Ä–æ–≤: {active_couriers}")
        
        logger.info("=== –®–∞–≥ 7: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–∞—Ä—à—Ä—É—Ç–æ–≤ –∫—É—Ä—å–µ—Ä–æ–≤ ===")
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –º–∞—Ä—à—Ä—É—Ç–æ–≤, –µ—Å–ª–∏ –Ω–µ—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π
        if total_assigned > 0:
            route_optimizer = optimize_courier_routes(
                assignment, optimized_polygons, conn, courier_service_times
            )
            logger.info("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –º–∞—Ä—à—Ä—É—Ç–æ–≤")
        else:
            logger.warning("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –º–∞—Ä—à—Ä—É—Ç–æ–≤ - –Ω–µ—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π")
        
        logger.info("=== –®–∞–≥ 8: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è ===")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–∞—Ä—à—Ä—É—Ç–æ–≤
        if total_assigned > 0:
            solution = generate_solution(
                route_optimizer, optimized_polygons, orders_df, 
                conn, 'test_decomposed_system_solution.json'
            )
        else:
            logger.warning("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ä–µ—à–µ–Ω–∏—è - –Ω–µ—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π")
            solution = None
        
        if solution:
            with open('test_decomposed_system_solution.json', 'w') as f:
                json.dump({"routes": solution.get('routes', [])}, f, indent=2)
            logger.info("–†–µ—à–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ test_decomposed_system_solution.json")
        
        execution_time = time.time() - start_time
        logger.info("=== –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ===")
        logger.info(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {execution_time:.2f} —Å–µ–∫—É–Ω–¥")
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        logger.info(f"   –ö—É—Ä—å–µ—Ä–æ–≤: {len(couriers_df)}")
        logger.info(f"   –ü–æ–ª–∏–≥–æ–Ω–æ–≤: {len(optimized_polygons)}")
        logger.info(f"   –ù–∞–∑–Ω–∞—á–µ–Ω–æ –ø–æ–ª–∏–≥–æ–Ω–æ–≤: {total_assigned}")
        logger.info(f"   –ê–∫—Ç–∏–≤–Ω—ã—Ö –∫—É—Ä—å–µ—Ä–æ–≤: {active_couriers}")
        logger.info(f"   –ù–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –∫—É—Ä—å–µ—Ä–æ–≤: {len(couriers_df) - active_couriers}")
        
        conn.close()
        decomposed_provider.close()
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞: {e}")
        import traceback
        logger.error(traceback.format_exc())
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        if 'decomposed_provider' in locals():
            decomposed_provider.close()
        
        raise

if __name__ == "__main__":
    create_decomposed_test()
